{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f0e9e91",
   "metadata": {},
   "source": [
    "# Implement K-Means clustering/ hierarchical clustering on sales_data_sample.csv dataset. Determine the number of clusters using the elbow method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef55cff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#Importing the required libraries.\n",
    "from sklearn.cluster import KMeans, k_means #For clustering\n",
    "from sklearn.decomposition import PCA #Linear Dimensionality reduction.\n",
    "df = pd.read_csv(\"sales_data_sample.csv\") #Loading the dataset.\n",
    "## Preprocessing \n",
    "df.head()\n",
    "df.shape \n",
    "df.describe()\n",
    "df.info()\n",
    "df.isnull().sum()\n",
    "df.dtypes\n",
    "df_drop  = ['ADDRESSLINE1', 'ADDRESSLINE2', 'STATUS','POSTALCODE', 'CITY', 'TERRITORY', 'PHONE', 'STATE', 'CONTACTFIRSTNAME', 'CONTACTLASTNAME', 'CUSTOMERNAME', 'ORDERNUMBER']\n",
    "df = df.drop(df_drop, axis=1) #Dropping the categorical uneccessary columns along with columns having null values. Can't fill the null values are there are alot of null values.\n",
    "df.isnull().sum()\n",
    "df.dtypes\n",
    "# Checking the categorical columns.\n",
    "df['COUNTRY'].unique()\n",
    "df['PRODUCTLINE'].unique()\n",
    "df['DEALSIZE'].unique()\n",
    "productline = pd.get_dummies(df['PRODUCTLINE']) #Converting the categorical columns. \n",
    "Dealsize = pd.get_dummies(df['DEALSIZE'])\n",
    "df = pd.concat([df,productline,Dealsize], axis = 1)\n",
    "df_drop  = ['COUNTRY','PRODUCTLINE','DEALSIZE'] #Dropping Country too as there are alot of countries. \n",
    "df = df.drop(df_drop, axis=1)\n",
    "df['PRODUCTCODE'] = pd.Categorical(df['PRODUCTCODE']).codes #Converting the datatype.\n",
    "df.drop('ORDERDATE', axis=1, inplace=True) #Dropping the Orderdate as Month is already included.\n",
    "df.dtypes #All the datatypes are converted into numeric\n",
    "## Plotting the Elbow Plot to determine the number of clusters. \n",
    "distortions = [] # Within Cluster Sum of Squares from the centroid\n",
    "K = range(1,10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(df)\n",
    "    distortions.append(kmeanModel.inertia_)   #Appeding the intertia to the Distortions \n",
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()\n",
    "## As the number of k increases Inertia decreases. \n",
    "## Observations: A Elbow can be observed at 3 and after that the curve decreases gradually. \n",
    "X_train = df.values #Returns a numpy array.\n",
    "X_train.shape\n",
    "model = KMeans(n_clusters=3,random_state=2) #Number of cluster = 3\n",
    "model = model.fit(X_train) #Fitting the values to create a model.\n",
    "predictions = model.predict(X_train) #Predicting the cluster values (0,1,or 2)\n",
    "unique,counts = np.unique(predictions,return_counts=True)\n",
    "counts = counts.reshape(1,3)\n",
    "counts_df = pd.DataFrame(counts,columns=['Cluster1','Cluster2','Cluster3'])\n",
    "counts_df.head()\n",
    "## Visualization \n",
    "pca = PCA(n_components=2) #Converting all the features into 2 columns to make it easy to visualize using Principal COmponent Analysis.\n",
    "reduced_X = pd.DataFrame(pca.fit_transform(X_train),columns=['PCA1','PCA2']) #Creating a DataFrame.\n",
    "reduced_X.head()\n",
    "#Plotting the normal Scatter Plot\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.scatter(reduced_X['PCA1'],reduced_X['PCA2'])\n",
    "model.cluster_centers_ #Finding the centriods. (3 Centriods in total. Each Array contains a centroids for particular feature )\n",
    "reduced_centers = pca.transform(model.cluster_centers_) #Transforming the centroids into 3 in x and y coordinates\n",
    "reduced_centers\n",
    "plt.figure(figsize=(14,10))\n",
    "plt.scatter(reduced_X['PCA1'],reduced_X['PCA2'])\n",
    "plt.scatter(reduced_centers[:,0],reduced_centers[:,1],color='black',marker='x',s=300) #Plotting the centriods\n",
    "reduced_X['Clusters'] = predictions #Adding the Clusters to the reduced dataframe.\n",
    "reduced_X.head()\n",
    "#Plotting the clusters \n",
    "plt.figure(figsize=(14,10))\n",
    "#                     taking the cluster number and first column           taking the same cluster number and second column      Assigning the color\n",
    "plt.scatter(reduced_X[reduced_X['Clusters'] == 0].loc[:,'PCA1'],reduced_X[reduced_X['Clusters'] == 0].loc[:,'PCA2'],color='slateblue')\n",
    "plt.scatter(reduced_X[reduced_X['Clusters'] == 1].loc[:,'PCA1'],reduced_X[reduced_X['Clusters'] == 1].loc[:,'PCA2'],color='springgreen')\n",
    "plt.scatter(reduced_X[reduced_X['Clusters'] == 2].loc[:,'PCA1'],reduced_X[reduced_X['Clusters'] == 2].loc[:,'PCA2'],color='indigo')\n",
    "\n",
    "\n",
    "plt.scatter(reduced_centers[:,0],reduced_centers[:,1],color='black',marker='x',s=300)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
