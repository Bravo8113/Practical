{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1803f417",
   "metadata": {},
   "source": [
    "# Given a bank customer, build a neural network-based classifier that can determine whether they will leave or not in the next 6 months.\n",
    "Dataset Description: The case study is from an open-source dataset from Kaggle. The dataset contains 10,000 sample points with 14 distinct features such as CustomerId, CreditScore, Geography, Gender, Age, Tenure, Balance, etc.\n",
    "Link to the Kaggle project: https://www.kaggle.com/barelydedicated/bank-customer-churn-modeling Perform following steps:\n",
    "1.\tRead the dataset.\n",
    "2.\tDistinguish the feature and target set and divide the data set into training and test sets.\n",
    "3.\tNormalize the train and test data.\n",
    "4.\tInitialize and build the model. Identify the points of improvement and implement the same.\n",
    "5.\tPrint the accuracy score and confusion matrix.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7a9833",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt #Importing the libraries\n",
    "df = pd.read_csv(\"Churn_Modelling.csv\")\n",
    "# Preprocessing. \n",
    "df.head()\n",
    "df.shape\n",
    "df.describe()\n",
    "df.isnull()\n",
    "df.isnull().sum()\n",
    "df.info()\n",
    "df.dtypes\n",
    "df.columns\n",
    "df = df.drop(['RowNumber', 'Surname', 'CustomerId'], axis= 1) #Dropping the unnecessary columns \n",
    "df.head()\n",
    "# Visualization\n",
    "def visualization(x, y, xlabel):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.hist([x, y], color=['red', 'green'], label = ['exit', 'not_exit'])\n",
    "    plt.xlabel(xlabel,fontsize=20)\n",
    "    plt.ylabel(\"No. of customers\", fontsize=20)\n",
    "    plt.legend()\n",
    "df_churn_exited = df[df['Exited']==1]['Tenure']\n",
    "df_churn_not_exited = df[df['Exited']==0]['Tenure']\n",
    "visualization(df_churn_exited, df_churn_not_exited, \"Tenure\")\n",
    "df_churn_exited2 = df[df['Exited']==1]['Age']\n",
    "df_churn_not_exited2 = df[df['Exited']==0]['Age']\n",
    "visualization(df_churn_exited2, df_churn_not_exited2, \"Age\")\n",
    "# Converting the Categorical Variables\n",
    "X = df[['CreditScore','Gender','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary']]\n",
    "states = pd.get_dummies(df['Geography'],drop_first = True)\n",
    "gender = pd.get_dummies(df['Gender'],drop_first = True)\n",
    "\n",
    "df = pd.concat([df,gender,states], axis = 1)\n",
    "# Splitting the training and testing Dataset\n",
    "df.head()\n",
    "X = df[['CreditScore','Age','Tenure','Balance','NumOfProducts','HasCrCard','IsActiveMember','EstimatedSalary','Male','Germany','Spain']]\n",
    "y = df['Exited']\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.30)\n",
    "# Normalizing the values with mean as 0 and Standard Deviation as 1\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train  = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "X_train\n",
    "X_test\n",
    "# Building the Classifier Model using Keras \n",
    "import keras #Keras is the wrapper on the top of tenserflow\n",
    "#Can use Tenserflow as well but won't be able to understand the errors initially. \n",
    "from keras.models import Sequential #To create sequential neural network\n",
    "from keras.layers import Dense #To create hidden layers\n",
    "classifier = Sequential()\n",
    "#To add the layers\n",
    "#Dense helps to contruct the neurons\n",
    "#Input Dimension means we have 11 features \n",
    "# Units is to create the hidden layers\n",
    "#Uniform helps to distribute the weight uniformly\n",
    "classifier.add(Dense(activation = \"relu\",input_dim = 11,units = 6,kernel_initializer = \"uniform\")) \n",
    "classifier.add(Dense(activation = \"relu\",units = 6,kernel_initializer = \"uniform\"))   #Adding second hidden layers\n",
    "classifier.add(Dense(activation = \"sigmoid\",units = 1,kernel_initializer = \"uniform\")) #Final neuron will be having siigmoid function\n",
    "classifier.compile(optimizer=\"adam\",loss = 'binary_crossentropy',metrics = ['accuracy']) #To compile the Artificial Neural Network. Ussed Binary crossentropy as we just have only two output\n",
    "classifier.summary() #3 layers created. 6 neurons in 1st,6neurons in 2nd layer and 1 neuron in last\n",
    "classifier.fit(X_train,y_train,batch_size=10,epochs=50) #Fitting the ANN to training dataset\n",
    "y_pred =classifier.predict(X_test)\n",
    "y_pred = (y_pred > 0.5) #Predicting the result\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "cm = confusion_matrix(y_test,y_pred)\n",
    "cm\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy\n",
    "plt.figure(figsize = (10,7))\n",
    "sns.heatmap(cm,annot = True)\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Truth')\n",
    "print(classification_report(y_test,y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
